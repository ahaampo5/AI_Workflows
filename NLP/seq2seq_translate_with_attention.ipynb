{"cells":[{"cell_type":"markdown","source":["# 독일어 -> 영어 번역기"],"metadata":{"id":"5B0ue8kFs6Lz"},"id":"5B0ue8kFs6Lz"},{"cell_type":"code","source":["!pip install --upgrade spacy # 영어, 독일어 토크나이저"],"metadata":{"id":"znOx5LFYqsVn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640848335452,"user_tz":-540,"elapsed":18131,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"1817215a-076b-4d4a-d02e-4b99a2f08be2"},"id":"znOx5LFYqsVn","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n","Collecting spacy\n","  Downloading spacy-3.2.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n","\u001b[K     |████████████████████████████████| 6.0 MB 4.3 MB/s \n","\u001b[?25hCollecting catalogue<2.1.0,>=2.0.6\n","  Downloading catalogue-2.0.6-py3-none-any.whl (17 kB)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n","Collecting pathy>=0.3.5\n","  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n","\u001b[K     |████████████████████████████████| 42 kB 1.1 MB/s \n","\u001b[?25hCollecting srsly<3.0.0,>=2.4.1\n","  Downloading srsly-2.4.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (451 kB)\n","\u001b[K     |████████████████████████████████| 451 kB 56.8 MB/s \n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n","Collecting typer<0.5.0,>=0.3.0\n","  Downloading typer-0.4.0-py3-none-any.whl (27 kB)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n","Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n","  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n","\u001b[K     |████████████████████████████████| 10.1 MB 35.9 MB/s \n","\u001b[?25hCollecting spacy-loggers<2.0.0,>=1.0.0\n","  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n","Collecting langcodes<4.0.0,>=3.2.0\n","  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 51.0 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n","Collecting spacy-legacy<3.1.0,>=3.0.8\n","  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n","Collecting thinc<8.1.0,>=8.0.12\n","  Downloading thinc-8.0.13-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (628 kB)\n","\u001b[K     |████████████████████████████████| 628 kB 46.3 MB/s \n","\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.6)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n","Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n","  Attempting uninstall: catalogue\n","    Found existing installation: catalogue 1.0.0\n","    Uninstalling catalogue-1.0.0:\n","      Successfully uninstalled catalogue-1.0.0\n","  Attempting uninstall: srsly\n","    Found existing installation: srsly 1.0.5\n","    Uninstalling srsly-1.0.5:\n","      Successfully uninstalled srsly-1.0.5\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 7.4.0\n","    Uninstalling thinc-7.4.0:\n","      Successfully uninstalled thinc-7.4.0\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 2.2.4\n","    Uninstalling spacy-2.2.4:\n","      Successfully uninstalled spacy-2.2.4\n","Successfully installed catalogue-2.0.6 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 spacy-3.2.1 spacy-legacy-3.0.8 spacy-loggers-1.0.1 srsly-2.4.2 thinc-8.0.13 typer-0.4.0\n"]}]},{"cell_type":"code","source":["!python -m spacy info # 버전 확인"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sgWeEwYgq0Il","executionInfo":{"status":"ok","timestamp":1640848352457,"user_tz":-540,"elapsed":17018,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"26f52703-8a92-4ddb-c252-11808095202f"},"id":"sgWeEwYgq0Il","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m\n","============================== Info about spaCy ==============================\u001b[0m\n","\n","spaCy version    3.2.1                         \n","Location         /usr/local/lib/python3.7/dist-packages/spacy\n","Platform         Linux-5.4.144+-x86_64-with-Ubuntu-18.04-bionic\n","Python version   3.7.12                        \n","Pipelines                                      \n","\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","from torchtext.legacy.datasets import Multi30k\n","from torchtext.legacy.data import Field, BucketIterator\n","\n","import spacy\n","import numpy as np\n","\n","import random\n","import math\n","import time"],"metadata":{"id":"-MBPGVNKq4dd","executionInfo":{"status":"ok","timestamp":1640848357767,"user_tz":-540,"elapsed":5314,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"-MBPGVNKq4dd","execution_count":3,"outputs":[]},{"cell_type":"code","source":["def set_seed(SEED):\n","    random.seed(SEED)\n","    np.random.seed(SEED)\n","    torch.manual_seed(SEED)\n","    torch.cuda.manual_seed(SEED)\n","    torch.backends.cudnn.deterministic = True\n","set_seed(2021)"],"metadata":{"id":"VdIkfGRQq_lF","executionInfo":{"status":"ok","timestamp":1640848357768,"user_tz":-540,"elapsed":15,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"VdIkfGRQq_lF","execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## 데이터 구축"],"metadata":{"id":"_vCTyO9mwYXA"},"id":"_vCTyO9mwYXA"},{"cell_type":"code","source":["!python -m spacy download en_core_web_sm # spacy에서 english tokenizer library 다운"],"metadata":{"id":"lJ92JBeLrQZA"},"id":"lJ92JBeLrQZA","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python -m spacy download de_core_news_sm # spacy에서 german tokenizer library 다운"],"metadata":{"id":"_YwYXWOmrtru"},"id":"_YwYXWOmrtru","execution_count":null,"outputs":[]},{"cell_type":"code","source":["spacy_de = spacy.load('de_core_news_sm')\n","spacy_en = spacy.load('en_core_web_sm')"],"metadata":{"id":"Zm0acR1zru9N","executionInfo":{"status":"ok","timestamp":1640848399421,"user_tz":-540,"elapsed":4855,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"Zm0acR1zru9N","execution_count":7,"outputs":[]},{"cell_type":"code","source":["def tokenize_de(text):\n","    \"\"\"\n","    Tokenizes German text from a string into a list of strings (tokens)\n","    \"\"\"\n","    return [tok.text for tok in spacy_de.tokenizer(text)]\n","\n","def tokenize_en(text):\n","    \"\"\"\n","    Tokenizes English text from a string into a list of strings (tokens)\n","    \"\"\"\n","    return [tok.text for tok in spacy_en.tokenizer(text)]"],"metadata":{"id":"O8AzGIBCrwOi","executionInfo":{"status":"ok","timestamp":1640848399422,"user_tz":-540,"elapsed":5,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"O8AzGIBCrwOi","execution_count":8,"outputs":[]},{"cell_type":"code","source":["# vocab 생성\n","SRC = Field(tokenize = tokenize_de, \n","            init_token = '<sos>', \n","            eos_token = '<eos>', \n","            lower = True)\n","\n","TRG = Field(tokenize = tokenize_en, \n","            init_token = '<sos>', \n","            eos_token = '<eos>', \n","            lower = True)"],"metadata":{"id":"K9b-2NlAsEO5","executionInfo":{"status":"ok","timestamp":1640848399954,"user_tz":-540,"elapsed":536,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"K9b-2NlAsEO5","execution_count":9,"outputs":[]},{"cell_type":"code","source":["train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), \n","                                                    fields = (SRC, TRG))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nImPESvrtCWz","executionInfo":{"status":"ok","timestamp":1640848417397,"user_tz":-540,"elapsed":17447,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"1f9de466-f673-4c08-c8eb-cf6e1d27c2f0"},"id":"nImPESvrtCWz","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["downloading training.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1.21M/1.21M [00:04<00:00, 301kB/s]\n"]},{"output_type":"stream","name":"stdout","text":["downloading validation.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 46.3k/46.3k [00:00<00:00, 91.2kB/s]\n"]},{"output_type":"stream","name":"stdout","text":["downloading mmt_task1_test2016.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 66.2k/66.2k [00:00<00:00, 88.3kB/s]\n"]}]},{"cell_type":"code","source":["print(f\"Number of training examples: {len(train_data.examples)}\")\n","print(f\"Number of validation examples: {len(valid_data.examples)}\")\n","print(f\"Number of testing examples: {len(test_data.examples)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tB18kOgftkl5","executionInfo":{"status":"ok","timestamp":1640848417398,"user_tz":-540,"elapsed":9,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"10f6685b-d85e-4b87-b637-31fe08735970"},"id":"tB18kOgftkl5","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training examples: 29000\n","Number of validation examples: 1014\n","Number of testing examples: 1000\n"]}]},{"cell_type":"code","source":["print(vars(train_data.examples[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7TDXnEX4vfmJ","executionInfo":{"status":"ok","timestamp":1640848417399,"user_tz":-540,"elapsed":8,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"0de26d24-8417-4287-c0d4-c050abf54ff8"},"id":"7TDXnEX4vfmJ","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["{'src': ['zwei', 'junge', 'weiße', 'männer', 'sind', 'im', 'freien', 'in', 'der', 'nähe', 'vieler', 'büsche', '.'], 'trg': ['two', 'young', ',', 'white', 'males', 'are', 'outside', 'near', 'many', 'bushes', '.']}\n"]}]},{"cell_type":"code","source":["SRC.build_vocab(train_data, min_freq = 2) # 토큰으로 인식하는 최소 빈도수\n","TRG.build_vocab(train_data, min_freq = 2)"],"metadata":{"id":"ppEXfOItvkT-","executionInfo":{"status":"ok","timestamp":1640848417957,"user_tz":-540,"elapsed":563,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"ppEXfOItvkT-","execution_count":13,"outputs":[]},{"cell_type":"code","source":["print(f\"Unique tokens in source (de) vocabulary: {len(SRC.vocab)}\")\n","print(f\"Unique tokens in target (en) vocabulary: {len(TRG.vocab)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VR-TQxL-viuD","executionInfo":{"status":"ok","timestamp":1640848417958,"user_tz":-540,"elapsed":11,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"b72a486f-2fcd-4259-a7c0-b177f1feba7e"},"id":"VR-TQxL-viuD","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Unique tokens in source (de) vocabulary: 7853\n","Unique tokens in target (en) vocabulary: 5893\n"]}]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a8STEi5_vyga","executionInfo":{"status":"ok","timestamp":1640848417959,"user_tz":-540,"elapsed":10,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"555a1f0b-d83a-4e6b-f070-bc52dd647d66"},"id":"a8STEi5_vyga","execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["BATCH_SIZE = 64\n","\n","train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n","    (train_data, valid_data, test_data), \n","    batch_size = BATCH_SIZE, \n","    device = device)"],"metadata":{"id":"yYPFy_kbv4_N","executionInfo":{"status":"ok","timestamp":1640848417959,"user_tz":-540,"elapsed":7,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"yYPFy_kbv4_N","execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["## 모델 구축"],"metadata":{"id":"z15tzAOawCjK"},"id":"z15tzAOawCjK"},{"cell_type":"code","source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        \n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers)\n","        self.dropout = nn.Dropout(p=dropout)\n","        \n","    def forward(self, src):\n","        # src = [src len, batch size]\n","        embedded = self.embedding(src)\n","        \n","        # embedded = [src len, batch size, emb dim] [LxNxH]\n","        outputs, (hidden, cell) = self.rnn(embedded)\n","        \n","        # outputs = [src len, batch size, hid dim * n directions]\n","        # hidden = [n layers * n directions, batch size, hid dim]\n","        # cell = [n layers * n directions, batch size, hid dim]\n","        \n","        # outputs are always from the top hidden layer\n","        \n","        return hidden, cell"],"metadata":{"id":"N4SrJm7ZwbrE","executionInfo":{"status":"ok","timestamp":1640848417960,"user_tz":-540,"elapsed":7,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"N4SrJm7ZwbrE","execution_count":17,"outputs":[]},{"cell_type":"code","source":["INPUT_DIM = len(SRC.vocab)\n","OUTPUT_DIM = len(TRG.vocab)\n","EMB_DIM = 128\n","HID_DIM = 128\n","N_LAYERS = 2\n","DROPOUT = 0.5\n","\n","encoder = Encoder(INPUT_DIM, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT)"],"metadata":{"id":"2UHnv5VwwfpE","executionInfo":{"status":"ok","timestamp":1640848417960,"user_tz":-540,"elapsed":7,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"2UHnv5VwwfpE","execution_count":18,"outputs":[]},{"cell_type":"code","source":["for i in train_iterator:\n","    print(i.src.shape)\n","    print(encoder(i.src)[0].shape, encoder(i.src)[1].shape)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Belnd1wFwgcs","executionInfo":{"status":"ok","timestamp":1640848418418,"user_tz":-540,"elapsed":464,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"2b737b13-b017-4d5d-dee6-f84ffb51339f"},"id":"Belnd1wFwgcs","execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([21, 64])\n","torch.Size([2, 64, 128]) torch.Size([2, 64, 128])\n"]}]},{"cell_type":"code","source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n","        super().__init__()\n","        self.output_dim = output_dim\n","        self.hid_dim = hid_dim\n","        self.n_layers = n_layers\n","        \n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers)\n","        self.fc_out = nn.Linear(hid_dim, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, input, hidden, cell):\n","        # input = [batch size] - 하나씩 만들어야함\n","        # hidden = [n layers * n directions, batch size, hid dim]\n","        # cell = [n layers * n directions, batch size, hid dim]\n","        \n","        # n directions in the decoder will both always be 1, therefore:\n","        # hidden = [n layers, batch size, hid dim]\n","        # context = [n layers, batch size, hid dim]\n","        \n","        input = input.unsqueeze(0)\n","        \n","        # input = [1, batch size]\n","        \n","        embedded = self.embedding(input)\n","        \n","        # embedded = [1, batch size, emb dim]\n","                \n","        output, (hidden, cell) = self.rnn(embedded)\n","        \n","        # output = [seq len, batch size, hid dim * n directions]\n","        # hidden = [n layers * n directions, batch size, hid dim]\n","        # cell = [n layers * n directions, batch size, hid dim]\n","        \n","        # seq len and n directions will always be 1 in the decoder, therefore:\n","        # output = [1, batch size, hid dim]\n","        # hidden = [n layers, batch size, hid dim]\n","        # cell = [n layers, batch size, hid dim]\n","        \n","        prediction = self.fc_out(output.squeeze(0))\n","        \n","        # prediction = [batch size, output dim]\n","        \n","        return prediction, hidden, cell"],"metadata":{"id":"Q5Ypm4-1xbzx","executionInfo":{"status":"ok","timestamp":1640848418419,"user_tz":-540,"elapsed":5,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"Q5Ypm4-1xbzx","execution_count":20,"outputs":[]},{"cell_type":"code","source":["decoder = Decoder(INPUT_DIM, EMB_DIM, HID_DIM, N_LAYERS, DROPOUT)"],"metadata":{"id":"w_gw6Jyn4LZ8","executionInfo":{"status":"ok","timestamp":1640848418420,"user_tz":-540,"elapsed":5,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"w_gw6Jyn4LZ8","execution_count":21,"outputs":[]},{"cell_type":"code","source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","        \n","        assert encoder.hid_dim == decoder.hid_dim, \\\n","            \"Hidden dimensions of encoder and decoder must be equal!\"\n","        assert encoder.n_layers == decoder.n_layers, \\\n","            \"Encoder and decoder must have equal number of layers!\"\n","        \n","    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n","        \n","        # src = [src len, batch size]\n","        # trg = [trg len, batch size]\n","        # teacher_forcing_ratio is probability to use teacher forcing\n","        # e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n","        \n","        batch_size = trg.shape[1]\n","        trg_len = trg.shape[0]\n","        trg_vocab_size = self.decoder.output_dim\n","        \n","        # tensor to store decoder outputs\n","        # import pdb; pdb.set_trace()\n","        outputs = torch.zeros(trg.size(0), batch_size, trg_vocab_size).to(device) # 텐서는 미리 만들어놔야한다\n","        \n","        # last hidden state of the encoder is used as the initial hidden state of the decoder\n","        hidden, cell = self.encoder(src)\n","        \n","        # first input to the decoder is the <sos> tokens\n","        input = trg[0, :]\n","        \n","        for t in range(1, trg_len):\n","            \n","            # insert input token embedding, previous hidden and previous cell states\n","            # receive output tensor (predictions) and new hidden and cell states\n","            output, hidden, cell = self.decoder(input, hidden, cell) # batch x output_dim\n","            \n","            # place predictions in a tensor holding predictions for each token\n","            outputs[t] = output\n","            \n","            # decide if we are going to use teacher forcing or not\n","            teacher_force = random.random() < teacher_forcing_ratio\n","            \n","            # get the highest predicted token from our predictions\n","            top1 = torch.max(output, dim=1)[1]\n","            \n","            # if teacher forcing, use actual next token as next input\n","            # if not, use predicted token\n","            input = trg[t,:] if teacher_force else top1\n","        \n","        return outputs"],"metadata":{"id":"qosKN0Fd2PZq","executionInfo":{"status":"ok","timestamp":1640848418420,"user_tz":-540,"elapsed":5,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"qosKN0Fd2PZq","execution_count":22,"outputs":[]},{"cell_type":"code","source":["seq2seq = Seq2Seq(encoder, decoder, device)"],"metadata":{"id":"jC5tfGU61uPw","executionInfo":{"status":"ok","timestamp":1640848418420,"user_tz":-540,"elapsed":4,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"jC5tfGU61uPw","execution_count":23,"outputs":[]},{"cell_type":"code","source":["for batch in train_iterator:\n","    print(batch.src.shape)\n","    print(batch.trg)\n","    print(seq2seq(batch.src, batch.trg).shape)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kKbgqPL84HQW","executionInfo":{"status":"ok","timestamp":1640848418950,"user_tz":-540,"elapsed":534,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"625ed927-70f7-497b-b4e3-e3d857134df7"},"id":"kKbgqPL84HQW","execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([30, 64])\n","tensor([[  2,   2,   2,  ...,   2,   2,   2],\n","        [  4,   4,   4,  ..., 113,   4,   4],\n","        [  9,  38, 353,  ...,  19,  26,   9],\n","        ...,\n","        [  1,   1,   1,  ...,   1,   1,   1],\n","        [  1,   1,   1,  ...,   1,   1,   1],\n","        [  1,   1,   1,  ...,   1,   1,   1]])\n","torch.Size([29, 64, 7853])\n"]}]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"xFeZFUQk5QBC"},"id":"xFeZFUQk5QBC"},{"cell_type":"code","source":["INPUT_DIM = len(SRC.vocab)\n","OUTPUT_DIM = len(TRG.vocab)\n","ENC_EMB_DIM = 256\n","DEC_EMB_DIM = 256\n","HID_DIM = 512\n","N_LAYERS = 2\n","ENC_DROPOUT = 0.5\n","DEC_DROPOUT = 0.5\n","\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n","\n","model = Seq2Seq(enc, dec, device)"],"metadata":{"id":"0s1QXC4J_hqu","executionInfo":{"status":"ok","timestamp":1640848418950,"user_tz":-540,"elapsed":3,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"0s1QXC4J_hqu","execution_count":25,"outputs":[]},{"cell_type":"code","source":["def init_weights(m):\n","    for name, param in m.named_parameters():\n","        nn.init.uniform_(param.data, -0.08, 0.08)\n","        \n","model.apply(init_weights)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WCMOPigI_sSj","executionInfo":{"status":"ok","timestamp":1640848419357,"user_tz":-540,"elapsed":410,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"d6fa3aef-eb03-41f8-b08d-da93d8d3fdf7"},"id":"WCMOPigI_sSj","execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Seq2Seq(\n","  (encoder): Encoder(\n","    (embedding): Embedding(7853, 256)\n","    (rnn): LSTM(256, 512, num_layers=2)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): Decoder(\n","    (embedding): Embedding(5893, 256)\n","    (rnn): LSTM(256, 512, num_layers=2)\n","    (fc_out): Linear(in_features=512, out_features=5893, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YIHGvBww_9-r","executionInfo":{"status":"ok","timestamp":1640848419358,"user_tz":-540,"elapsed":8,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"39efd92a-bc12-4243-f302-d23150fe087f"},"id":"YIHGvBww_9-r","execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 13,898,501 trainable parameters\n"]}]},{"cell_type":"code","source":["optimizer = optim.Adam(model.parameters())"],"metadata":{"id":"YxgbFv5r__tE","executionInfo":{"status":"ok","timestamp":1640848419358,"user_tz":-540,"elapsed":5,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"YxgbFv5r__tE","execution_count":28,"outputs":[]},{"cell_type":"code","source":["# pad 토큰에 loss 흐르지 말도록\n","TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n","\n","criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"],"metadata":{"id":"0q7HRdpPAD_2","executionInfo":{"status":"ok","timestamp":1640848419359,"user_tz":-540,"elapsed":5,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"0q7HRdpPAD_2","execution_count":29,"outputs":[]},{"cell_type":"code","source":["def train(model, iterator, optimizer, criterion, clip):\n","    \n","    model.train()\n","    \n","    epoch_loss = 0\n","    \n","    for i, batch in enumerate(iterator):\n","        \n","        src = batch.src\n","        trg = batch.trg\n","        \n","        optimizer.zero_grad()\n","        \n","        # with sos token\n","        output = model(src, trg, teacher_forcing_ratio=0.5) # L x N x prob\n","        \n","        # trg = [trg len, batch size]\n","        # output = [trg len, batch size, output dim]\n","        \n","        output_dim = output.shape[-1] \n","        \n","        output = output[1:,:,:]\n","        trg = trg[1:,:]\n","        \n","        # trg = [(trg len - 1) * batch size]\n","        # output = [(trg len - 1) * batch size, output dim]\n","        \n","        loss = criterion(output.view(-1, output_dim), trg.view(-1)) # must be 2D, 1D shape\n","        \n","        loss.backward()\n","        \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"metadata":{"id":"MNJ1PenJAGiE","executionInfo":{"status":"ok","timestamp":1640848419359,"user_tz":-540,"elapsed":5,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"MNJ1PenJAGiE","execution_count":30,"outputs":[]},{"cell_type":"code","source":["def evaluate(model, iterator, criterion):\n","    \n","    model.eval()\n","    \n","    epoch_loss = 0\n","    \n","    with torch.no_grad():\n","    \n","        for i, batch in enumerate(iterator):\n","\n","            src = batch.src\n","            trg = batch.trg\n","\n","            output = model(src, trg, teacher_forcing_ratio=0.0) #turn off teacher forcing\n","\n","            #trg = [trg len, batch size]\n","            #output = [trg len, batch size, output dim]\n","\n","            output_dim = output.shape[-1]\n","            \n","            output = output[1:,:,:]\n","            trg = trg[1:,:]\n","\n","            #trg = [(trg len - 1) * batch size]\n","            #output = [(trg len - 1) * batch size, output dim]\n","\n","            loss = criterion(output.view(-1, output_dim), trg.view(-1))\n","            \n","            epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"metadata":{"id":"TytTv4tBEE1_","executionInfo":{"status":"ok","timestamp":1640848444488,"user_tz":-540,"elapsed":509,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"TytTv4tBEE1_","execution_count":31,"outputs":[]},{"cell_type":"code","source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"metadata":{"id":"fKqueDDlEevW","executionInfo":{"status":"ok","timestamp":1640848444895,"user_tz":-540,"elapsed":3,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"fKqueDDlEevW","execution_count":32,"outputs":[]},{"cell_type":"code","source":["N_EPOCHS = 5\n","CLIP = 1\n","\n","best_valid_loss = float('inf')\n","\n","for epoch in range(N_EPOCHS):\n","    \n","    start_time = time.time()\n","    \n","    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n","    valid_loss = evaluate(model, valid_iterator, criterion)\n","    \n","    end_time = time.time()\n","    \n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), 'tut1-model.pt')\n","    \n","    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"],"metadata":{"id":"TFJvpXGzEhGT"},"id":"TFJvpXGzEhGT","execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.load_state_dict(torch.load('tut1-model.pt'))\n","\n","test_loss = evaluate(model, test_iterator, criterion)\n","\n","print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"],"metadata":{"id":"0R_RN2cXB59J"},"id":"0R_RN2cXB59J","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## With Attention"],"metadata":{"id":"5LSRerGOLaTU"},"id":"5LSRerGOLaTU"},{"cell_type":"code","source":["class Encoder(nn.Module):\n","    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n","        super().__init__()\n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional=True)\n","        self.fc = nn.Linear(enc_hid_dim*2, dec_hid_dim)\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, src):\n","        \n","        # src = [src len, batch size]\n","        \n","        embedded = self.embedding(src)\n","        \n","        # embedded = [src len, batch size, emb dim]\n","        \n","        outputs, hidden = self.rnn(embedded)\n","                \n","        # outputs = [src len, batch size, hid dim * num directions]\n","        # hidden = [n layers * num directions, batch size, hid dim]\n","        \n","        # hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n","        # outputs are always from the last layer\n","        \n","        # hidden [-2, :, : ] is the last of the forwards RNN [batch, hid_dim]\n","        # hidden [-1, :, : ] is the last of the backwards RNN [batch, hid_dim]\n","        \n","        # initial decoder hidden is final hidden state of the forwards and backwards \n","        # encoder RNNs fed through a linear layer\n","        hidden = torch.cat([hidden[-2,:,:], hidden[-1,:,:]], dim=1)\n","        hidden = torch.tanh(self.fc(hidden))\n","\n","        # outputs = [src len, batch size, enc hid dim * 2]\n","        # hidden = [batch size, dec hid dim]\n","        \n","        return outputs, hidden"],"metadata":{"id":"zMZLEHWLMapl","executionInfo":{"status":"ok","timestamp":1640853594939,"user_tz":-540,"elapsed":470,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"zMZLEHWLMapl","execution_count":129,"outputs":[]},{"cell_type":"code","source":["class Attention(nn.Module):\n","    def __init__(self, enc_hid_dim, dec_hid_dim):\n","        super().__init__()\n","        \n","        self.attn = nn.Linear(dec_hid_dim+enc_hid_dim*2, dec_hid_dim)\n","        self.v = nn.Linear(dec_hid_dim, 1, bias=False) #\n","        \n","    def forward(self, hidden, encoder_outputs): # time step t의 hidden\n","        print(hidden.shape, encoder_outputs.shape)\n","        # hidden = [batch size, dec hid dim]\n","        # encoder_outputs = [src len, batch size, enc hid dim * 2]\n","        \n","        batch_size = encoder_outputs.shape[1]\n","        src_len = encoder_outputs.shape[0]\n","        \n","        # repeat decoder hidden state src_len times - 한번에 계산하려고\n","        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n","        \n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","        \n","        # hidden = [batch size, src len, dec hid dim]\n","        # encoder_outputs = [batch size, src len, enc hid dim * 2]\n","        print(hidden.shape, encoder_outputs.shape)\n","        tmp = torch.cat((hidden, encoder_outputs), dim=-1)\n","        print(tmp.shape)\n","        energy = self.attn(tmp)\n","        \n","        # energy = [batch size, src len, dec hid dim]\n","\n","        attention = torch.softmax(self.v(energy).squeeze(-1), dim=-1)\n","        \n","        # attention = [batch size, src len]\n","        \n","        return attention"],"metadata":{"id":"vxg_iNzLLclB","executionInfo":{"status":"ok","timestamp":1640853595390,"user_tz":-540,"elapsed":5,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"vxg_iNzLLclB","execution_count":130,"outputs":[]},{"cell_type":"code","source":["class Decoder(nn.Module):\n","    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n","        super().__init__()\n","\n","        self.output_dim = output_dim\n","        self.attention = attention\n","        \n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        self.rnn = nn.GRU(enc_hid_dim*2 + emb_dim, dec_hid_dim, bidirectional=False)\n","        self.fc_out = nn.Linear(enc_hid_dim*2 + dec_hid_dim + emb_dim, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, input, hidden, encoder_outputs):\n","             \n","        # input = [batch size]\n","        # hidden = [batch size, dec hid dim]\n","        # encoder_outputs = [src len, batch size, enc hid dim * 2]\n","        \n","        input = input.unsqueeze(0)\n","        \n","        # input = [1, batch size]\n","        \n","        embedded = self.embedding(input)\n","        \n","        # embedded = [1, batch size, emb dim]\n","        # print('test', hidden.shape, encoder_outputs.shape)\n","        \n","        a = self.attention(hidden, encoder_outputs)\n","                \n","        # a = [batch size, src len]\n","        \n","        a = a.unsqueeze(1)\n","        \n","        # a = [batch size, 1, src len]\n","        \n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","        \n","        # encoder_outputs = [batch size, src len, enc hid dim * 2]\n","        \n","        weighted = torch.bmm(a, encoder_outputs)\n","        # 설명 : [batch, 1, src_len] x [batch, src_len, enc_hid_dim * 2]\n","        # 마지막 두개를 매트릭스로 생각하여 연산\n","\n","        # weighted = [batch size, 1, enc hid dim * 2]\n","        \n","        weighted = weighted.permute(1, 0, 2)\n","        \n","        # weighted = [1, batch size, enc hid dim * 2]\n","        \n","        rnn_input = torch.cat((weighted, embedded), dim=-1)\n","        \n","        # rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n","            \n","        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n","        \n","        # output = [seq len, batch size, dec hid dim * n directions]\n","        # hidden = [n layers * n directions, batch size, dec hid dim]\n","        \n","        # seq len, n layers and n directions will always be 1 in this decoder, therefore:\n","        # output = [1, batch size, dec hid dim]\n","        # hidden = [1, batch size, dec hid dim]\n","        # this also means that output == hidden\n","        assert (output == hidden).all()\n","        \n","        embedded = embedded.squeeze(0)\n","        output = output.squeeze(0)\n","        weighted = weighted.squeeze(0)\n","        \n","        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=-1))\n","        \n","        # prediction = [batch size, output dim]\n","        \n","        return prediction, hidden.squeeze(0), a"],"metadata":{"id":"vTA4ndyGLec8","executionInfo":{"status":"ok","timestamp":1640855106505,"user_tz":-540,"elapsed":552,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"vTA4ndyGLec8","execution_count":166,"outputs":[]},{"cell_type":"code","source":["class Seq2Seq(nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","        \n","    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n","        \n","        # src = [src len, batch size]\n","        # trg = [trg len, batch size]\n","        # teacher_forcing_ratio is probability to use teacher forcing\n","        # e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n","        \n","        batch_size = src.shape[1]\n","        trg_len = trg.shape[0]\n","        trg_vocab_size = self.decoder.output_dim\n","        \n","        # tensor to store decoder outputs\n","        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(device)\n","        \n","        # encoder_outputs is all hidden states of the input sequence, back and forwards\n","        # hidden is the final forward and backward hidden states, passed through a linear layer\n","        encoder_outputs, hidden = self.encoder(src)\n","                \n","        # first input to the decoder is the <sos> tokens\n","        input = trg[0,:]\n","        \n","        for t in range(1, trg_len):\n","            \n","            # insert input token embedding, previous hidden state and all encoder hidden states\n","            # receive output tensor (predictions) and new hidden state\n","            output, hidden, _ = self.decoder(input, hidden, encoder_outputs)\n","            \n","            # place predictions in a tensor holding predictions for each token\n","            outputs[t] = output\n","            \n","            # decide if we are going to use teacher forcing or not\n","            teacher_force = random.random() < teacher_forcing_ratio\n","            \n","            # get the highest predicted token from our predictions\n","            top1 = torch.max(output, dim=-1)[1]\n","            \n","            # if teacher forcing, use actual next token as next input\n","            # if not, use predicted token\n","            input = trg[t] if teacher_force else top1\n","\n","        return outputs"],"metadata":{"id":"WmEQlKxjZYvC","executionInfo":{"status":"ok","timestamp":1640855106506,"user_tz":-540,"elapsed":3,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"WmEQlKxjZYvC","execution_count":167,"outputs":[]},{"cell_type":"markdown","source":["## Training"],"metadata":{"id":"64J1DybpaSkE"},"id":"64J1DybpaSkE"},{"cell_type":"code","source":["INPUT_DIM = len(SRC.vocab)\n","OUTPUT_DIM = len(TRG.vocab)\n","ENC_EMB_DIM = 256\n","DEC_EMB_DIM = 256\n","ENC_HID_DIM = 256\n","DEC_HID_DIM = 256\n","ENC_DROPOUT = 0.5\n","DEC_DROPOUT = 0.5\n","\n","attn = Attention(ENC_HID_DIM, DEC_HID_DIM)\n","enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n","dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n","\n","model = Seq2Seq(enc, dec, device)"],"metadata":{"id":"JEdvfy_taR-A","executionInfo":{"status":"ok","timestamp":1640855107868,"user_tz":-540,"elapsed":3,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"JEdvfy_taR-A","execution_count":168,"outputs":[]},{"cell_type":"code","source":["def init_weights(m):\n","    for name, param in m.named_parameters():\n","        if 'weight' in name:\n","            nn.init.normal_(param.data, mean=0, std=0.01)\n","        else:\n","            nn.init.constant_(param.data, 0)\n","            \n","model.apply(init_weights)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9rfDGgxBa3aQ","executionInfo":{"status":"ok","timestamp":1640855108341,"user_tz":-540,"elapsed":2,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"39430629-12f5-46dc-8312-ff8d73ee70ea"},"id":"9rfDGgxBa3aQ","execution_count":169,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Seq2Seq(\n","  (encoder): Encoder(\n","    (embedding): Embedding(7853, 256)\n","    (rnn): GRU(256, 256, bidirectional=True)\n","    (fc): Linear(in_features=512, out_features=256, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): Decoder(\n","    (attention): Attention(\n","      (attn): Linear(in_features=768, out_features=256, bias=True)\n","      (v): Linear(in_features=256, out_features=1, bias=False)\n","    )\n","    (embedding): Embedding(5893, 256)\n","    (rnn): GRU(768, 256)\n","    (fc_out): Linear(in_features=1024, out_features=5893, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")"]},"metadata":{},"execution_count":169}]},{"cell_type":"code","source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ykpX-YrobBz7","executionInfo":{"status":"ok","timestamp":1640855108787,"user_tz":-540,"elapsed":2,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"695cbd55-f697-4e8f-d9ee-435f051869fe"},"id":"ykpX-YrobBz7","execution_count":170,"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 11,465,221 trainable parameters\n"]}]},{"cell_type":"code","source":["optimizer = optim.Adam(model.parameters())"],"metadata":{"id":"8dx_VoQKbDA_","executionInfo":{"status":"ok","timestamp":1640855109753,"user_tz":-540,"elapsed":4,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"8dx_VoQKbDA_","execution_count":171,"outputs":[]},{"cell_type":"code","source":["TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n","\n","criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"],"metadata":{"id":"AC1TTZAJbBCf","executionInfo":{"status":"ok","timestamp":1640855016424,"user_tz":-540,"elapsed":2,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"AC1TTZAJbBCf","execution_count":160,"outputs":[]},{"cell_type":"code","source":["def train(model, iterator, optimizer, criterion, clip):\n","    \n","    model.train()\n","    \n","    epoch_loss = 0\n","    \n","    for i, batch in enumerate(iterator):\n","        \n","        src = batch.src\n","        trg = batch.trg\n","        \n","        optimizer.zero_grad()\n","        \n","        output = model(src, trg, teacher_forcing_ratio=0.)\n","        \n","        # trg = [trg len, batch size]\n","        # output = [trg len, batch size, output dim]\n","        \n","        output_dim = output.shape[-1]\n","        \n","        output = output[1:].view(-1, output_dim)\n","        trg = trg[1:].view(-1)\n","        \n","        # trg = [(trg len - 1) * batch size]\n","        # output = [(trg len - 1) * batch size, output dim]\n","        \n","        loss = criterion(output, trg)\n","        \n","        loss.backward()\n","        \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)"],"metadata":{"id":"uBA6Ya64bELq","executionInfo":{"status":"ok","timestamp":1640853597395,"user_tz":-540,"elapsed":3,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"uBA6Ya64bELq","execution_count":138,"outputs":[]},{"cell_type":"code","source":["train(model, train_iterator, optimizer, criterion, 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"5luhQPerbwlr","executionInfo":{"status":"error","timestamp":1640853603915,"user_tz":-540,"elapsed":6038,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"ce992ec0-59f1-470e-bf75-a456e915f113"},"id":"5luhQPerbwlr","execution_count":139,"outputs":[{"output_type":"stream","name":"stdout","text":["test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n","test torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 256]) torch.Size([26, 64, 512])\n","torch.Size([64, 26, 256]) torch.Size([64, 26, 512])\n","torch.Size([64, 26, 768])\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-139-78609681d657>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-138-73d93ab58428>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["## Inference"],"metadata":{"id":"eYwEkW06c2BY"},"id":"eYwEkW06c2BY"},{"cell_type":"code","source":["def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n","    \n","    model.eval()\n","\n","    tokens = [src_field.init_token] + sentence + [src_field.eos_token]\n","    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n","    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n","\n","    with torch.no_grad():\n","        encoder_outputs, hidden = model.encoder(src_tensor)\n","\n","    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n","    attentions = torch.zeros((max_len, 1, len(src_indexes))).to(device)\n","\n","    for i in range(max_len):\n","        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n","\n","        with torch.no_grad():\n","            output, hidden, attention = model.decoder(trg_tensor, hidden, encoder_outputs)\n","\n","        attentions[i] = attention\n","        pred_token = output.argmax(dim=1).item()\n","\n","        trg_indexes.append(pred_token)\n","\n","        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n","            break\n","\n","    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n","\n","    return trg_tokens[1:], attentions[:len(trg_tokens)-1]"],"metadata":{"id":"0dZ7p40dg724","executionInfo":{"status":"ok","timestamp":1640855121508,"user_tz":-540,"elapsed":444,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"0dZ7p40dg724","execution_count":172,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker"],"metadata":{"id":"mqjciEwTjTRJ","executionInfo":{"status":"ok","timestamp":1640855121933,"user_tz":-540,"elapsed":2,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"mqjciEwTjTRJ","execution_count":173,"outputs":[]},{"cell_type":"code","source":["def display_attention(sentence, translation, attention):\n","    \n","    fig = plt.figure(figsize=(10,10))\n","    ax = fig.add_subplot(111)\n","    \n","    attention = attention.squeeze(1).cpu().detach().numpy()\n","    \n","    cax = ax.matshow(attention, cmap='bone')\n","   \n","    ax.tick_params(labelsize=15)\n","    \n","    x_ticks = [''] + ['<sos>'] + [t.lower() for t in sentence] + ['<eos>']\n","    y_ticks = [''] + translation\n","     \n","    ax.set_xticklabels(x_ticks, rotation=45)\n","    ax.set_yticklabels(y_ticks)\n","\n","    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n","    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n","\n","    plt.show()\n","    plt.close()"],"metadata":{"id":"SL_hGv5DjUXR","executionInfo":{"status":"ok","timestamp":1640855122366,"user_tz":-540,"elapsed":2,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}}},"id":"SL_hGv5DjUXR","execution_count":174,"outputs":[]},{"cell_type":"code","source":["example_idx = 12\n","\n","src = vars(train_data.examples[example_idx])['src']\n","trg = vars(train_data.examples[example_idx])['trg']\n","\n","print(f'src = {src}')\n","print(f'trg = {trg}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fOYBf9WGjXLT","executionInfo":{"status":"ok","timestamp":1640855125500,"user_tz":-540,"elapsed":11,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"3b8b1b6e-edb2-421e-d67c-791c0394c803"},"id":"fOYBf9WGjXLT","execution_count":175,"outputs":[{"output_type":"stream","name":"stdout","text":["src = ['ein', 'schwarzer', 'hund', 'und', 'ein', 'gefleckter', 'hund', 'kämpfen', '.']\n","trg = ['a', 'black', 'dog', 'and', 'a', 'spotted', 'dog', 'are', 'fighting']\n"]}]},{"cell_type":"code","source":["translation, attention = translate_sentence(src, SRC, TRG, model, device)\n","\n","print(f'predicted trg = {translation}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JXNXYTUFjX42","executionInfo":{"status":"ok","timestamp":1640855126088,"user_tz":-540,"elapsed":597,"user":{"displayName":"JCdata","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18221923975897538727"}},"outputId":"7f876311-2420-4f87-9c18-7419ca6662b2"},"id":"JXNXYTUFjX42","execution_count":176,"outputs":[{"output_type":"stream","name":"stdout","text":["test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","test torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 256]) torch.Size([11, 1, 512])\n","torch.Size([1, 11, 256]) torch.Size([1, 11, 512])\n","torch.Size([1, 11, 768])\n","predicted trg = ['rappelling', 'tile', 'shields', 'stocking', 'bulldog', 'mixed', 'participant', 'pins', 'adjusts', 'message', 'taxi', 'graze', 'casino', 'effort', 'vehicles', 'comb', 'plaster', 'unison', 'man', 'backed', 'tap', 'applied', 'nintendo', '<unk>', 'rock', 'aluminum', 'swampy', 'popping', 'claw', 'risk', 'power', 'isle', 'grill', 'foods', 'darkened', 'vacuuming', 'amplifier', 'mountain', 'paws', 'information', 'gardening', 'walked', 'awaiting', 'goods', 'theme', 'sculpting', 'lizard', 'scrabble', 'paddy', 'patio']\n"]}]},{"cell_type":"code","source":["display_attention(src, translation, attention)"],"metadata":{"id":"yUsGITYPjYmc"},"id":"yUsGITYPjYmc","execution_count":null,"outputs":[]},{"cell_type":"code","source":["example_idx = 14\n","\n","src = vars(valid_data.examples[example_idx])['src']\n","trg = vars(valid_data.examples[example_idx])['trg']\n","\n","print(f'src = {src}')\n","print(f'trg = {trg}')"],"metadata":{"id":"zEbbBM-EjZmu"},"id":"zEbbBM-EjZmu","execution_count":null,"outputs":[]},{"cell_type":"code","source":["translation, attention = translate_sentence(src, SRC, TRG, model, device)\n","\n","print(f'predicted trg = {translation}')\n","\n","display_attention(src, translation, attention)"],"metadata":{"id":"pA025BtvjbHh"},"id":"pA025BtvjbHh","execution_count":null,"outputs":[]},{"cell_type":"code","source":["example_idx = 18\n","\n","src = vars(test_data.examples[example_idx])['src']\n","trg = vars(test_data.examples[example_idx])['trg']\n","\n","print(f'src = {src}')\n","print(f'trg = {trg}')"],"metadata":{"id":"sLhjtVlWjb-1"},"id":"sLhjtVlWjb-1","execution_count":null,"outputs":[]},{"cell_type":"code","source":["translation, attention = translate_sentence(src, SRC, TRG, model, device)\n","\n","print(f'predicted trg = {translation}')\n","\n","display_attention(src, translation, attention)"],"metadata":{"id":"bBBgUM5Cjctd"},"id":"bBBgUM5Cjctd","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchtext.data.metrics import bleu_score\n","\n","def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\n","    \n","    trgs = []\n","    pred_trgs = []\n","    \n","    for datum in data:\n","        \n","        ...\n","        \n","    return bleu_score(pred_trgs, trgs)"],"metadata":{"id":"XWCrlFXFjdkf"},"id":"XWCrlFXFjdkf","execution_count":null,"outputs":[]},{"cell_type":"code","source":["bleu_score = calculate_bleu(test_data, SRC, TRG, model, device)\n","\n","print(f'BLEU score = {bleu_score*100:.2f}')"],"metadata":{"id":"g2fvmf-gjeWb"},"id":"g2fvmf-gjeWb","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"seq2seq_translate_with_attention.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}